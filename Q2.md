# Question 2 - 30-Sided Die Game  

## Two players are presented with a 30-sided die. The first player chooses a number between 1 and 30. The second player can then choose a number between 1 and 30 (they may not choose the same number as the first player). The die is then rolled and the person whose choice is closest to the die roll gets money equal to the die roll. Is it preferable to go first or second, and what strategy should be applied?  

### Context  
Someone asked this question in a math Discord server. It caught my attention and I spent the better part of an hour figuring this (and the proceeding more general case) out. I was supposed to be studying for a probability midterm the next day. Thankfully, it was easier than this question.  

### Solution  
This is actually a pretty intuitive and straightforward question to solve. The optimal choice for P1 (regardless of if P2 is able to beat him) is logically somewhere between 15 and 30. Trial and error will give you the correct answer fairly quickly, but I think this is a more systematic solution.  

Let $x_1$ be P1's choice and $x_2$ be P2's choice. It is evident that P2's optimal response must be $x_1 + 1$ or $x_1 - 1$. Any other choice will underperform relative to the aforementioned that is closest to it. For example $x_1 + 3$ will necessarily underperform relative to $x_1 + 1$, since it captures a smaller subset of the possible outcomes. Considering the extremes, if $x_1 = 2$, P2 should respond with $x_2 = x_1 + 1$. Likewise, if $x_1 = 29$, P2 should respond with $x_2 = x_1 - 1$. Since lower choices of $x_1$ lend itself to $x_2 = x_1 + 1$ and vice versa, there will be a "flipping point" at which P2's optimal decision shifts from $x_1 + 1$ to $x_1 - 1$.  

Thus, the expected payoff of choosing $x_1 + 1$ is greater than choosing $x_1 - 1$ if:  

$$
\large \frac{1}{30} \sum_{d=x_1+1}^{30} d \geq \frac{1}{30} \sum_{d=1}^{x_1-1} d
$$

The 1/30 term on both sides represent the probability of any die roll $x$. The left hand side then iterates from $x_1 + 1$ to 30. Multiplying these values by the probability of it occuring (1/30) gives P2's expected earnings from choosing $x_1 + 1$. Likewise, the right hand side gives P2's expected earnings from choosing $x_1 - 1$, as it iterates from 1 to $x_1 - 1$.  

The 1/30 on both sides cancel out. The sum on the right hand side is fairly easy, as it is the arithmetic sum from 1 to $x_1 - 1$. There are multiple ways to solve the sum on the left hand side. One is to consider it as the difference between the arithmetic sum from 1 to 30 and the arithmetic sum from 1 to $x_1 + 1$. This yields a difference of two standard equations for the sum of an arithmetic series, as such:  

$$
\large \frac{30*31}{2} - \frac{x_1(x_1+1)}{2} \geq \frac{(x_1-1)x_1}{2}
$$

Simplifying yields:  

$$
\large 930 - x_1^2 - x_1 \geq x_1^2 - x_1
$$

The first-order terms cancel and the final answer is $x_1 \leq \sqrt{465} \approx 21.56$. To recap, this means that if P1 picks 21 or below, P2 should pick $x_1 + 1$ and if P1 picks 22 or above, P2 should pick $x_1 - 1$. The intuitive step here is that either 21 or 22 should be P1's optimal pick. One can reason this by recognizing that the advantage P2 can derive by selecting $x_1 - 1$ or $x_1 + 1$ erodes at 21.56, meaning that (if it was possible) P1 selecting 21.56 would result P2 to have the same expected gain regardless of if he selects $x_1 - 1$ or $x_1 + 1$.  

The total gain to be captured from this game is simply the expected value of the dice roll, $(30+1)/2 = 15.5$. If P1 picks 21, P2 will respond with 22, causing P1's expected gain to be

$$
\frac{1}{30} \large \sum_{n=1}^{21} n = \frac{1}{30} \frac{21*22}{2} = 7.7
$$

In this case, P2's gain will be the complement of this value (15.5 - 7.7 = 7.8)

If P1 picks 22, P2 will respond with 21. We can go through the same set of calculations to find P1's expected gain, or we can recognize that this is simply the previous scenario (P1 picking 21 and P2 responding with 22) with the players reversed. Hence, P1's expected gain from this will be 7.8, while P2's expected gain is relegated to 7.7. Therefore, **It is preferable to go first, and select 22**.  

While I was solving this question, I thought of a follow up:  

### Is being Player 1 always the optimal choice, regardless of the number of faces of the die?  

Intuitively, it feels like P1 always has an advantage, but there isn't an obvious way to justify it. The key here is that the discretization of the game allows P1 to be able to force an advantage. Consider the continuous game with an analog spinner instead of a die and with P2 picking "over" or "under" P1's choice. So if P1 picks $x_1$, P2 can choose an infinitesimally larger or infinitesimally smaller number than $x_1$. Now, because P2 is not bound to pick $x_1 + 1$ or $x_1 - 1$ but rather can further optimize by picking $x_1 + 0.0...1$ and $x_1 - 0.0...1$, and outcomes may be non-integer, the "flipping point" will be slightly different. We can solve for this by using an integral instead of a series:  

$$
\Large \int\limits_1^a x \ dx = \int\limits_a^{30} x \ dx
$$  

This is a simple indefinite integral, and a evaluates to approximately 21.22 (note that this is different than from 21.56). Nevertheless, in this scenario, P1's optimal move would be to pick 21.22. This would result in P2's choice of "over" or "under" being irrelevant. Since the game is continuous, the 15.5 value of the spinner is split perfectly split 7.75-7.75 between both players (note that when calculating the expected value of either player, we must divide by 29, not 30, since the length of the interval in the continuous game is 30 - 1 = 29). Anyways, this means that with optimal play, neither player can ever forcibly get more than 50% of the total expected gain in the continuous version as P1 is forced to cut the expected gain into two equal pieces (lest P2 pick the largest section), rendering P2's decision irrelevant.  

Now, going back to the discrete game with the die. Clearly P1 *can* force an advantage. When initially trying to come up with a proof that P1 can *always* force an advantage, I came upon an interesting shortcut.  

Recall how we calculated P1's expected gain when he picks 22, after having calculated his gain when picking 21. Since we knew that the "flipping point" (where P2 should choose $x_1 - 1$ instead of $x_1 + 1$) was between 21 and 22, we knew that P2 would have to flip his decision to $x_1 - 1$ if we picked 22. This would result in equivilant (but flipped) expectations for P1 and P2 as in the case where P1 picked 21. This itself is sufficient proof that P1 can *always* either force an advantage or split the expected gain in half. Let's formalize a bit.  

Let $N$ be the "flipping point" 
