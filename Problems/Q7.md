# Question 7 - Unbalanced Coin

## You have a biased coin with a probability $p$ of tossing heads and $1-p$ of tossing tails. You toss it until you get two heads in a row. How many times do you expect to toss it?

### Context  
The question was given as a bonus question on a practice final exam for MATH 356 (Honours Probability) at McGill. It looks like a pretty tough question at first but becomes very simple when you come up with the idea to split the problem up into two states and solve the recurrence relation. I thought of it as I had covered FSMs in a separate (engineering) class that week, which operate in a similar manner. 

### Solution  
We can treat this problem as having three states $S_0$, $S_1$, and $S_2$. $S_0$ is the state where a head was **not** observed in the previous toss and thus requires two consecutive heads to end the game. The game starts at $S_0$. $S_1$ is the state where a head was observed in the previous toss, thus requiring only one more head to end the game. $S_2$ is when two heads have just been tossed in a row (and therefore the game is over). $S_2$ isn't too important (since the game ends the instant we reach it), defining it just helps us develop the structure.  

Now, let's say we are at State 0 ($S_0$). If we toss a head (with probability $p$), we go to $S_1$. If we toss a tail (with probability $1-p$), we stay in $S_0$. So we can define the semi-recursive formula:  

$$
E_0 = 1 + pE_1 + (1-p)E_0
$$  

Where $E_0$ and $E_1$ are the expected number of tosses from $S_0$ and $S_1$, respectively. So the line above says that the expected number of tosses from State 0 is equal to p times the expected number of tosses from State 1 plus (1-p) times the expected number of tosses from State 0. The +1 accounts for the toss we just made.  

We can repeat the same formula for when we are at State 1. This time, a head sends us to State 2 (and ends the game) while a tail sends us back to State 0. So we can systematically write the formula:  

$$
E_1 = 1 + pE_2 + (1-p)E_0
$$  

However, the game immediately ends when we reach $S_2$, so $E_2=0$ (ie. "0" tosses from State 2 to end the game). Therefore the second expression can be simplified to:  

$$
E_1 = 1 + (1-p)E_0
$$

We now have two equations and two variables ($E_1$ and $E_0$). As a side note, these equations that we have just derived are actually identical to the system of equations produced when finding the expected time to absorption from a given transient state in a Markov Chain. We care about the expected number of tosses from the starting state $S_0$, so we want to calculate $E_0$. Substituting in the second equation into the first one:  

$$
E_0 = 1 + p(1 + (1-p)E_0) + (1-p)E_0
$$

We solve for $E_0$, which gives us:  

$$
\large E_0 = \frac{1+p}{p^2}
$$  

If you have a measure theory (or advanced stats?) background you might notice this only shows that *if* the expectation exists, then it is equal to $\frac{1+p}{p^2}$. Formally, we would have to prove the existence and uniqueness of the expectation (ie. how can we know that the expectation is finite?). Anyways, that's beyond the scope of this problem (but pretty easy, especially when you realize that the game is just a Markov chain under the hood). 
